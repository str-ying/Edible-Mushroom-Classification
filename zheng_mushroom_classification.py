# -*- coding: utf-8 -*-
"""Updated Tuned and Metrics of Fixed_Mushroom_preprocessing & SVM, KNN, DecTree, LogReg

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Dpjf8gfx4d4rcWvORqMf6eTTlIm_BqLy
"""

import os
from google.colab import drive
drive.mount('/content/gdrive')
os.chdir('/content/gdrive/MyDrive/MA440')
!pwd 
!ls

#libraries

import pandas as pd
from pandas import read_csv
import statistics
import matplotlib.pyplot as plt
from sklearn.compose import make_column_transformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score,confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier,plot_tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score , plot_confusion_matrix , plot_roc_curve , plot_precision_recall_curve , classification_report
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

data = read_csv('final_processed_data_with_dummies.csv')

x1 = data.drop(['Unnamed: 0'], axis = 1)

x2 = x1.drop('class', axis = 1)

y = x1['class']

#X_train, X_test, y_train, y_test = train_test_split(x2, y, test_size=0.15, random_state=101)
X_train, X_test, y_train, y_test = train_test_split(x2, y, test_size=0.25, random_state=42)

"""# SVM MODEL"""

#SVM

svs_model = SVC(C=10.0, kernel='rbf') #OG: C =1.0
svs_model.fit(X_train, y_train)

y_pred1 = svs_model.predict(X_test)
y_pred1

#SVM tune
from sklearn.model_selection import GridSearchCV

svs_clf = GridSearchCV(svs_model, {
    'C': [1, 10, 20],
    'kernel' : ['rbf', 'linear']
    }, cv=5, return_train_score=False, scoring = 'accuracy')

svs_clf.fit(X_train, y_train)
svs_clf.best_params_

#SVM Confusion Matrix and Classification 

print(classification_report(y_test, y_pred1))
cm1 = confusion_matrix(y_test, y_pred1)
cmd_obj = ConfusionMatrixDisplay(cm1, display_labels=['edible', 'inedible'])
cmd_obj.plot()
cmd_obj.ax_.set( title='SVM Confusion Matrix')

#SVM accuracy 

print('Accuracy for SVM:',accuracy_score(y_test,y_pred1))

#SVM Cohen Kappa

from sklearn.metrics import cohen_kappa_score
cohen_score1 = round(cohen_kappa_score(y_test, y_pred1),3)
print("Kappa Score:", cohen_score1)

"""# LOGISTIC REGRESSION MODEL

"""

#Logistic Regression

log_model = LogisticRegression(C= 25,penalty= 'l2')
log_model.fit(X_train, y_train)

y_pred = log_model.predict(X_test)
y_pred

#Logistic reg tune
from sklearn.model_selection import GridSearchCV

param = {'penalty': ['l1', 'l2'],'C':[0.001,.009,0.01,.09,1,5,10,25]}
lr_clf = GridSearchCV(log_model,param, cv=5, return_train_score=False, scoring = 'accuracy')

lr_clf.fit(X_train, y_train)
lr_clf.best_params_

lr_clf.cv_results_
df = pd.DataFrame(lr_clf.cv_results_)
df[['param_C', 'param_penalty', 'mean_test_score']]

#Logistic confusion matrix and classification report

print(classification_report(y_test, y_pred))

cm2 = confusion_matrix(y_test, y_pred)
cmd_obj = ConfusionMatrixDisplay(cm2, display_labels=['edible', 'inedible'])
cmd_obj.plot()
cmd_obj.ax_.set( title='Logistic Regression Confusion Matrix')

#Logistic accuracy

print('Accuracy for Log Reg:',accuracy_score(y_test,y_pred))

#Logistic Cohen Kappa
cohen_score2 = round(cohen_kappa_score(y_test, y_pred), 3)
print("Kappa Score:", cohen_score2)

"""# KNN MODEL

"""

#KNN

dict1 = {'uniform':[],'distance':[]}
for i in dict1.keys():
    for k in range(1,21,2):
        clf = KNeighborsClassifier(n_neighbors = k,weights = i)
        clf.fit(X_train,y_train)
        y_predict = clf.predict(X_test)
        dict1[i].append(accuracy_score(y_test,y_predict))

dict2 = {'1':[],'2':[]}
for i in dict2.keys():
    for j in range(1,21,2):
        clf = KNeighborsClassifier(n_neighbors = j,weights = 'distance',p = int(i))
        clf.fit(X_train,y_train)
        y_pred2 = clf.predict(X_test)
        dict2[i].append(accuracy_score(y_test,y_pred2))

knn_model = KNeighborsClassifier(n_neighbors = j,weights = 'distance',p = int(i))
knn_model.fit(X_train,y_train)
y_pred2 = clf.predict(X_test)

#KNN confusion matrix and classification report
print(classification_report(y_test, y_pred2))

cm3 = confusion_matrix(y_test, y_pred2)
cmd_obj = ConfusionMatrixDisplay(cm3, display_labels=['edible', 'inedible'])
cmd_obj.plot()
cmd_obj.ax_.set( title='KNN Confusion Matrix')

#KNN accuracy 
print('Accuracy for KNN:',accuracy_score(y_test,y_pred2))

#KNN Cohen Kappa
cohen_score3 = round(cohen_kappa_score(y_test, y_pred2),3)
print("Kappa Score:", cohen_score3)

"""# DECISION TREE MODEL

"""

#Decision Tree

cre = {'gini':[],'entropy':[]}
for i in cre.keys():
    for j in range(1,20):
        dec = DecisionTreeClassifier(criterion = i,max_depth = j)
        dec.fit(X_train,y_train)
        y_pred4 = dec.predict(X_test)
        cre[i].append(accuracy_score(y_test,y_pred4))

dec = DecisionTreeClassifier(criterion = 'entropy',max_depth = 6)
dec.fit(X_train,y_train)
y_pred4 = dec.predict(X_test)

plt.figure(figsize = [18,18])
q = plot_tree(dec,filled=True,feature_names = x2.columns,node_ids = True)

#Decision Tree confusion matrix and classification report
print(classification_report(y_test, y_pred4))

cm4 = confusion_matrix(y_test, y_pred4)
cmd_obj = ConfusionMatrixDisplay(cm4, display_labels=['edible', 'inedible'])
cmd_obj.plot()
cmd_obj.ax_.set( title='Decision Tree Confusion Matrix')

#Decision Tree accurary

print('Accuracy for Decision Tree:',accuracy_score(y_test,y_pred4))

#Decision Tree Cohen Kappa

cohen_score4 = round(cohen_kappa_score(y_test, y_pred4),3)
print("Kappa Score:", cohen_score4)

"""# RANDOM FOREST MODEL"""

import numpy as np
foldername = '/content/gdrive/MyDrive/MA440'
filename = foldername + '/cleansed_mushroom2.csv'
cleansed_mushroom = pd.read_csv(filename)

filename2 = foldername + '/preprocessed_mushroom_data.csv'
labels = pd.read_csv(filename2)

#poisonous = 1 
#edible = 0
labels = pd.DataFrame(labels['class'])
features = cleansed_mushroom.drop('class', axis = 1)
features = pd.get_dummies(data = features)

labels = np.array(labels)
features = np.array(features)

train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)

base_model = RandomForestClassifier(n_estimators = 1000, random_state = 42)
base_model.fit(train_features, train_labels)
base_predictions = base_model.predict(test_features)
#base_accuracy = model_accuracy(norm_predictions, test_labels)

# print('The accuracy of the base model is:', base_accuracy*100, '%')
# print('woo!')
confusionmat = confusion_matrix(test_labels,base_predictions)
print('Confusion matrix:')
print(confusion_matrix(test_labels,base_predictions))
print('Test accuracy for Decision Tree:',accuracy_score(test_labels,base_predictions)*100, '%')

from sklearn.metrics import accuracy_score , plot_confusion_matrix , plot_roc_curve , plot_precision_recall_curve , classification_report
print(classification_report(test_labels, base_predictions))

cm5 = confusion_matrix(test_labels, base_predictions)
cmd_obj = ConfusionMatrixDisplay(cm5, display_labels=['edible', 'inedible'])
cmd_obj.plot()
cmd_obj.ax_.set( title='Random Forest Confusion Matrix')

print('Accuracy for Decision Tree:',accuracy_score(test_labels,base_predictions))

cohen_score5 = round(cohen_kappa_score(test_labels, base_predictions),3)
print("Kappa Score:", cohen_score5)

from sklearn.ensemble import AdaBoostClassifier

#model evaluation
from sklearn.metrics import accuracy_score , plot_confusion_matrix , plot_roc_curve , plot_precision_recall_curve , classification_report



final_model_mush = AdaBoostClassifier(n_estimators=42)

final_model_mush.fit(X_train, y_train)
predictions = final_model_mush.predict(X_test)

print(classification_report(y_test, predictions))

cm6 = confusion_matrix(y_test, predictions)
cmd_obj = ConfusionMatrixDisplay(cm6, display_labels=['edible', 'inedible'])
cmd_obj.plot()
cmd_obj.ax_.set( title='Adaboost Confusion Matrix')

print('Accuracy for Adaboost:',accuracy_score(y_test,predictions))

cohen_score6 = round(cohen_kappa_score(y_test, predictions),3)
print("Kappa Score:", cohen_score6)

#Comparison

print('Accuracy for SVM:',accuracy_score(y_test,y_pred1))
print('Accuracy for Log Reg:',accuracy_score(y_test,y_pred))
print('Accuracy for KNN:',accuracy_score(y_test,y_pred2))
print('Accuracy for Decision Tree:',accuracy_score(y_test,y_pred4))
print('Accuracy for Random Forest:',accuracy_score(test_labels,base_predictions))
print('Accuracy for Adaboost:',accuracy_score(y_test,predictions))

classifiers = [svs_model,
               log_model,
               knn_model,
               dec,
               base_model, 
               final_model_mush]
for cls in classifiers:
    cls.fit(X_train, y_train)

fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15,10))

for cls, ax in zip(classifiers, axes.flatten()):
    plot_confusion_matrix(cls, 
                          X_test, 
                          y_test, 
                          ax=ax, 
                          cmap='Blues',
                         display_labels=['edible', 'inedible'])
    ax.title.set_text(type(cls).__name__)
plt.tight_layout()  
plt.show()

svm_acc = round(accuracy_score(y_test,y_pred1),3)
lr_acc = round(accuracy_score(y_test,y_pred), 3)
knn_acc = round(accuracy_score(y_test,y_pred2),3)
dt_acc = round(accuracy_score(y_test,y_pred4),3)
rf_acc = round(accuracy_score(test_labels,base_predictions),3)
ada_acc = round(accuracy_score(y_test,predictions),3)

import matplotlib.pyplot as plt
fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
langs = ['SVM', 'Logisitic Regression', 'KNN', 'Decision Tree', 'Random Forest', 'Adaboost']
accuracy = [svm_acc,lr_acc,knn_acc,dt_acc, rf_acc, ada_acc]
pps = ax.bar(langs,accuracy)
plt.title("Model Accuracy Scores")
plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.xticks(rotation = 45)
for p in pps:
   height = p.get_height()
   ax.annotate('{}'.format(height),
      xy=(p.get_x() + p.get_width() / 2, height),
      xytext=(0, 3), # 3 points vertical offset
      textcoords="offset points",
      ha='center', va='bottom')
   
plt.show()

print('Cohen''s Kappa score for SVM:',cohen_score1)
print('Cohen''s Kappa score for Log Reg:',cohen_score2)
print('Cohen''s Kappa score for KNN:',cohen_score3)
print('Cohen''s Kappa score for Decision Tree:',cohen_score4)
print('Cohen''s Kappa score for Random Forest:',cohen_score5)
print('Cohen''s Kappa score for Adaboost:',cohen_score6)

fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
langs = ['SVM', 'Logisitic Regression', 'KNN', 'Decision Tree', 'Random Forest', 'Adaboost']
accuracy = [cohen_score1,cohen_score2,cohen_score3,cohen_score4, cohen_score5, cohen_score6]
pps = ax.bar(langs,accuracy)
plt.title("Model Kappa Scores")
plt.xlabel('Model')
plt.ylabel('Kappa Score')
plt.xticks(rotation = 45)
for p in pps:
   height = p.get_height()
   ax.annotate('{}'.format(height),
      xy=(p.get_x() + p.get_width() / 2, height),
      xytext=(0, 3), # 3 points vertical offset
      textcoords="offset points",
      ha='center', va='bottom')
   
plt.show()

#SVM ROC and AUC
import sklearn
from sklearn import metrics

fpr, tpr, threshold = metrics.roc_curve(y_test, y_pred1)
roc_auc = metrics.auc(fpr, tpr)
plt.figure(1)
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr, label= 'AUC = {:.3f}'.format(roc_auc))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('SVM ROC curve')
plt.legend(loc='best')
plt.show()

#Logisitc Regression ROC and AUC
probs = log_model.predict_proba(X_test)
preds = probs[:,1]
fpr, tpr, threshold = metrics.roc_curve(y_test, preds)
roc_auc = metrics.auc(fpr, tpr)
plt.figure(1)
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr, label= 'AUC = {:.3f}'.format(roc_auc))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('Logistic Regression ROC curve')
plt.legend(loc='best')
plt.show()

#KNN ROC and AUC
probs = knn_model.predict_proba(X_test)
preds = probs[:,1]
fpr, tpr, threshold = metrics.roc_curve(y_test, preds)
roc_auc = metrics.auc(fpr, tpr)
plt.figure(1)
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr, label= 'AUC = {:.3f}'.format(roc_auc))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('KNN ROC curve')
plt.legend(loc='best')
plt.show()

#Decision Tree ROC and AUC
probs = dec.predict_proba(X_test)
preds = probs[:,1]
fpr, tpr, threshold = metrics.roc_curve(y_test, preds)
roc_auc = metrics.auc(fpr, tpr)
plt.figure(1)
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr, label= 'AUC = {:.3f}'.format(roc_auc))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('Decision Tree ROC curve')
plt.legend(loc='best')
plt.show()

#Random Forest ROC and AUC
probs = base_model.predict_proba(test_features)
preds = probs[:,1]
fpr, tpr, threshold = metrics.roc_curve(test_labels, preds)
roc_auc = metrics.auc(fpr, tpr)
plt.figure(1)
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr, label= 'AUC = {:.3f}'.format(roc_auc))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('Random Forest ROC curve')
plt.legend(loc='best')
plt.show()

#Adaboost ROC and AUC
probs = final_model_mush.predict_proba(X_test)
preds = probs[:,1]
fpr, tpr, threshold = metrics.roc_curve(y_test, preds)
roc_auc = metrics.auc(fpr, tpr)
plt.figure(1)
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr, label= 'AUC = {:.3f}'.format(roc_auc))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('Adaboost ROC curve')
plt.legend(loc='best')
plt.show()

corr_mat = x2.corr()
corr_mat.style.background_gradient(cmap = 'Greens')

# Compare Algorithms
import pandas
import matplotlib.pyplot as plt
from sklearn import model_selection
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC

models = []
models.append(('LR', LogisticRegression(C= 25,penalty= 'l2')))
models.append(('KNN', KNeighborsClassifier()))
models.append(('DT', DecisionTreeClassifier()))
models.append(('SVM', SVC(C=10.0, kernel='rbf')))
models.append(('RF', RandomForestClassifier(n_estimators = 1000, random_state = 42)))

seed = 7
results = []
names = []
scoring = 'accuracy'
for name, model in models:
	kfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle=True)
	cv_results = model_selection.cross_val_score(model, x2, y, cv=kfold, scoring=scoring)
	results.append(cv_results)
	names.append(name)
	msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
	print(msg)

fig = plt.figure()
fig.suptitle('Algorithm Comparison')
ax = fig.add_subplot(111)
plt.boxplot(results)
ax.set_xticklabels(names)
plt.show()